{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codeT5_pretrain_1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us8x03jd0RDx"
      },
      "source": [
        "#All\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dxGVMRKccLw"
      },
      "source": [
        "## Set up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYC6K_mY2lmC",
        "outputId": "28edee09-017e-4ee7-8e3e-0f9f5493ac71"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YALHrJycdhD",
        "outputId": "7d6d2b80-b65c-4a6c-8c64-349316d8a4d4"
      },
      "source": [
        "print(\"Installing dependencies...\")\n",
        "%tensorflow_version 2.x\n",
        "# !pip install --user --upgrade tensorflow-probability\n",
        "# !pip install -U tf-nightly-gpu\n",
        "# !pip install -U tensorflow-gcs-config==2.1.2\n",
        "!pip install -q t5==0.7.1\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import gin\n",
        "import t5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing dependencies...\n",
            "\u001b[K     |████████████████████████████████| 174kB 6.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 4.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4MB 7.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 42.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 45.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.1MB 44.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 42.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 43.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 42.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCbvk8HLNtzL",
        "outputId": "b176e427-d18e-4344-c11e-9ca448d8857b"
      },
      "source": [
        "ON_CLOUD = True\n",
        "\n",
        "if ON_CLOUD:\n",
        "  print(\"Setting up GCS access...\")\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"v3-8\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU zdetection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting up GCS access...\n",
            "Running on TPU: grpc://10.110.233.242:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzw-OyyM5nVO",
        "outputId": "e7aa1934-a9cc-4a89-a253-bb8c9a0c04a1"
      },
      "source": [
        "import gin\n",
        "import subprocess\n",
        "gin.parse_config_file(\n",
        "        'gs://t5-data/pretrained_models/base/operative_config.gin'\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:system_path_file_exists:gs://t5-data/pretrained_models/base/operative_config.gin\n",
            "ERROR:root:Path not found: gs://t5-data/pretrained_models/base/operative_config.gin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParsedConfigFileIncludesAndImports(filename='gs://t5-data/pretrained_models/base/operative_config.gin', imports=['t5.models.mesh_transformer', 't5.data.sentencepiece_vocabulary', 'mesh_tensorflow.optimize', 'mesh_tensorflow.transformer.dataset', 'mesh_tensorflow.transformer.learning_rate_schedules', 'mesh_tensorflow.transformer.t2t_vocabulary', 'mesh_tensorflow.transformer.transformer_layers', 'mesh_tensorflow.transformer.utils'], includes=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LH2XTnkO--T"
      },
      "source": [
        "## dumping dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6oLM1a2OIUN"
      },
      "source": [
        "from random import shuffle\n",
        "\n",
        "def dumping_dataset(split, shuffle_files = False):\n",
        "    del shuffle_files\n",
        "    \n",
        "    train_files = []\n",
        "\n",
        "    train_files.extend(list(map(lambda x: x.strip(), subprocess.run(['gsutil', 'ls', f'gs://cotext/data/github_repos/sample_content/python/train/*.tsv'], stdout=subprocess.PIPE).stdout.splitlines())))\n",
        "    train_files.extend(list(map(lambda x: x.strip(), subprocess.run(['gsutil', 'ls', f'gs://cotext/data/github_repos/sample_content/java/train/*.tsv'], stdout=subprocess.PIPE).stdout.splitlines())))\n",
        "\n",
        "    shuffle(train_files)\n",
        "\n",
        "    print(train_files[0])\n",
        "\n",
        "    ds = tf.data.TextLineDataset(\n",
        "       train_files\n",
        "    )\n",
        "    ds = ds.map(lambda *ex: dict(zip(['title', 'text'], ['None',ex[0]])))\n",
        "\n",
        "    return ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7_sr1EiOaqf"
      },
      "source": [
        "\n",
        "t5.data.TaskRegistry.remove('dumping_dataset')\n",
        "t5.data.TaskRegistry.add(\n",
        "    'dumping_dataset',\n",
        "    dataset_fn = dumping_dataset,\n",
        "    splits = ['train'],\n",
        "    text_preprocessor =  functools.partial(\n",
        "        t5.data.preprocessors.rekey,\n",
        "        key_map = {'inputs': None, 'targets': 'text'},\n",
        "    ),\n",
        "    token_preprocessor = t5.data.preprocessors.unsupervised,\n",
        "    metric_fns = [],\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQabnVj3OgIX"
      },
      "source": [
        "t5.data.MixtureRegistry.remove('all_codeT5')\n",
        "t5.data.MixtureRegistry.add(\n",
        "    'all_codeT5',\n",
        "    [\n",
        "        'dumping_dataset',\n",
        "    ],\n",
        "    default_rate = 1.0,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32MP_WmdRpfx"
      },
      "source": [
        "## Pre train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F0V0tQmRkry"
      },
      "source": [
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
        "\n",
        "\n",
        "MODEL_SIZE = 'base'\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    'small': (1, 256, 16),\n",
        "    'base': (2, 128, 8),\n",
        "    'large': (8, 64, 4),\n",
        "    '3B': (8, 16, 1),\n",
        "    '11B': (8, 16, 1),\n",
        "}[MODEL_SIZE]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g8MUdXxFymk"
      },
      "source": [
        "if ON_CLOUD:\n",
        "  %reload_ext tensorboard\n",
        "  import tensorboard as tb\n",
        "tb.notebook.start(\"--logdir \" + 'gs://t5_training/models/code/code_all_v1/base')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFuvRpqpRui_"
      },
      "source": [
        "model = t5.models.MtfModel(\n",
        "  model_dir = 'gs://t5_training/models/code/code_all_v1/base',\n",
        "  tpu = TPU_ADDRESS,\n",
        "  tpu_topology = TPU_TOPOLOGY,\n",
        "  model_parallelism = model_parallelism,\n",
        "  batch_size = train_batch_size,\n",
        "  sequence_length = {'inputs': 1024, 'targets': 1024},\n",
        "  learning_rate_schedule = 0.001,\n",
        "  save_checkpoints_steps = 1000,\n",
        "  keep_checkpoint_max = 5,\n",
        "  iterations_per_loop = 100,\n",
        ")\n",
        "\n",
        "model.train(mixture_or_task_name = 'all_codeT5', steps = 1000000+200000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}